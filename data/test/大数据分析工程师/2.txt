1、使用Hadoop技术栈Spark、Flink、Kafka等实现海量数据的分布式离线、实时计算。
2、通过数据开发，支持跨领域数据分析产品交付，支撑无线产品商业成功和效率提升。
3、在整个数据全生命周期，进行数据质量和数据安全的治理。
专业知识要求：
1、计算机、软件工程、等相关专业，掌握至少一种编程语言及工具：GO、Python、Java、C、C++等；
2、熟练掌握数据库技术，熟悉关系型数据（MySQL,Oracle等）、图数据库等主流数据库；
3、熟悉大数据处理框架：Hadoop、spark、Hive、Flink、Kafka、storm等。